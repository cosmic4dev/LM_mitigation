{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92116fc2ff5d4364b29dd6bf5719525a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f76a0550d0e14d6ba561ffaa59f7f798",
              "IPY_MODEL_36c30507cb104d24bc8a4b2b107b18b1",
              "IPY_MODEL_36ca86b5bf5f460aa62dcf23a285c25a"
            ],
            "layout": "IPY_MODEL_95afe16903d4497a98ca89365fe17bba"
          }
        },
        "f76a0550d0e14d6ba561ffaa59f7f798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de941cba78ca491a80b2fb612c7fb063",
            "placeholder": "​",
            "style": "IPY_MODEL_adb82733a085407abb20683b4094cfad",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "36c30507cb104d24bc8a4b2b107b18b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffa88b64b994ed3b6b28495c94df8a7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcbcbe49fe754f78972d403e1ff44a5d",
            "value": 2
          }
        },
        "36ca86b5bf5f460aa62dcf23a285c25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce0da31260b4458ada9c19cff4e5afa",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7368489f4744c29f01d8b4f2bc637a",
            "value": " 2/2 [00:06&lt;00:00,  3.10s/it]"
          }
        },
        "95afe16903d4497a98ca89365fe17bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de941cba78ca491a80b2fb612c7fb063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb82733a085407abb20683b4094cfad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ffa88b64b994ed3b6b28495c94df8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbcbe49fe754f78972d403e1ff44a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ce0da31260b4458ada9c19cff4e5afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7368489f4744c29f01d8b4f2bc637a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## input\n",
        "case 1"
      ],
      "metadata": {
        "id": "nZOPFyUXtuu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WFkqkBI7tLyf"
      },
      "outputs": [],
      "source": [
        "# message의 '원문'과 '유해 요소'는 임의로 넣은 것임.\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "원문: \"그 사람은 정말 구제불능이다.\"\n",
        "유해 요소: ['구제불능']\n",
        "Negative Span: \"구제불능\"\n",
        "작업 목표:\n",
        "1. 주어진 '원문'에서 감지된 '유해 요소'를 기반으로, 문맥과 의미를 유지하며 부드럽게 완화된 표현으로 대체하세요.\n",
        "2. 완화된 새 문장을 생성하세요.\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "case 2"
      ],
      "metadata": {
        "id": "O-Rmzcs0tuHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중 처리 (임시로 lock)\n",
        "# messages = [\n",
        "#     {\n",
        "#         \"role\": \"user\",\n",
        "#         \"content\": \"\"\"\n",
        "# 작업 대상 문장:\n",
        "# 1. \"그 사람은 정말 구제불능이다.\" (유해 요소: ['구제불능'], Negative Span: \"구제불능\")\n",
        "# 2. \"그 사람은 정말 무식하다.\" (유해 요소: ['무식'], Negative Span: \"무식\")\n",
        "# 작업 목표:\n",
        "# 1. 각 문장에서 '유해 요소'를 문맥과 의미를 유지하며 완화된 표현으로 대체하세요.\n",
        "# 2. 각 문장에 대한 완화된 결과를 생성하세요.\n",
        "#         \"\"\"\n",
        "#     }\n",
        "# ]\n"
      ],
      "metadata": {
        "id": "zOk6YUretSkg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "case 3.\n",
        "감지된 유해 표현과 원무을 구조적으로 분리하여 입력하기"
      ],
      "metadata": {
        "id": "amiIfzJgt15N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "원문: \"그 사람은 정말 구제불능이다.\"\n",
        "유해 요소: ['구제불능']\n",
        "작업 목표:\n",
        "1. '유해 요소'를 문맥과 의미를 유지하며 완화된 표현으로 대체하세요.\n",
        "2. 완화된 문장을 반환하세요.\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "원문: \"그 사람은 정말 무식하다.\"\n",
        "유해 요소: ['무식']\n",
        "작업 목표:\n",
        "1. '유해 요소'를 문맥과 의미를 유지하며 완화된 표현으로 대체하세요.\n",
        "2. 완화된 문장을 반환하세요.\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "8FQdrSywtrEz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 메시지 템플릿"
      ],
      "metadata": {
        "id": "hiej-ABDuKOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "원문: \"그 사람은 정말 구제불능이다.\"\n",
        "유해 요소: ['구제불능']\n",
        "Negative Span: \"구제불능\"\n",
        "작업 목표:\n",
        "1. '유해 요소'를 문맥과 의미를 유지하며 완화된 표현으로 대체하세요.\n",
        "2. 완화된 새 문장을 반환하세요.\n",
        "결과:\"\"\"\n",
        "\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "sOFaz2VpuH9s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가로 긴 문장이 들어왔을 때 핸들링하는 방법도 고려하면 좋을듯."
      ],
      "metadata": {
        "id": "O3Yg5Bh-uaOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate #  모델의 GPU/TPU 가속화와 분산 학습을 도와주는 라이브러리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu1eUO9euwGE",
        "outputId": "eb314f1a-22a3-4226-e94b-faf58e5320b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Bllossom/llama-3.2-Korean-Bllossom-3B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Bllossom/llama-3.2-Korean-Bllossom-3B\")\n",
        "\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "print(\"모델 로딩 완료!\")\n",
        "\n",
        "#모델과 토크나이저를 한 번만 로드한 후, 메모리에 유지합니다.\n",
        "#이를 위해 별도의 셀에 모델 로드 코드를 작성하고, 이후 실험에서는 해당 객체를 재사용합니다.\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# input_text = \"\"\"\n",
        "# 유해 요소: ['구제불능'].\n",
        "# 기존 문장: 그런 인간은 정말 구제불능이다.\n",
        "# 수정된 문장:\"\"\"\n",
        "\n",
        "\n",
        "# inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# output = model.generate(\n",
        "#     inputs['input_ids'],\n",
        "#     attention_mask=inputs['attention_mask'],\n",
        "#     max_new_tokens=50,\n",
        "#     temperature=0.7,\n",
        "#     top_k=50,\n",
        "#     top_p=0.9\n",
        "# )\n",
        "\n",
        "# print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "92116fc2ff5d4364b29dd6bf5719525a",
            "f76a0550d0e14d6ba561ffaa59f7f798",
            "36c30507cb104d24bc8a4b2b107b18b1",
            "36ca86b5bf5f460aa62dcf23a285c25a",
            "95afe16903d4497a98ca89365fe17bba",
            "de941cba78ca491a80b2fb612c7fb063",
            "adb82733a085407abb20683b4094cfad",
            "3ffa88b64b994ed3b6b28495c94df8a7",
            "bcbcbe49fe754f78972d403e1ff44a5d",
            "6ce0da31260b4458ada9c19cff4e5afa",
            "3a7368489f4744c29f01d8b4f2bc637a"
          ]
        },
        "id": "HpMWtbHZvI9q",
        "outputId": "e1749220-5c28-4888-d6eb-e5e3b9a50edd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92116fc2ff5d4364b29dd6bf5719525a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 로딩 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  checkpoint save\n",
        "# 로컬에 저장\n",
        "# model.save_pretrained(\"./local_model\")\n",
        "# tokenizer.save_pretrained(\"./local_model\")\n"
      ],
      "metadata": {
        "id": "a-eeAK9CyWBS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 저장을 위한 mount\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nzRa2tY3QRR",
        "outputId": "05d4f80d-6cea-4596-d4e8-c610bb300131"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장할 경로 설정\n",
        "save_path = \"/content/drive/MyDrive/yaife/model_checkpoint\"\n",
        "\n",
        "# 모델 및 토크나이저 저장\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"{save_path}에 저장됨.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_gUep2s3Z92",
        "outputId": "50f24848-c698-4010-f849-4653aedf7daa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yaife/model_checkpoint에 저장됨.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reuse\n",
        "# 로컬 디렉터리에서 로드\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"./local_model\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"./local_model\")\n"
      ],
      "metadata": {
        "id": "XY3fA6mdydJ8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#test\n",
        "input_text = \"\"\"\n",
        "유해 요소: ['구제불능'].\n",
        "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
        "기존 문장: 그런 인간은 정말 구제불능이다.\n",
        "수정된 문장:\"\"\"\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n"
      ],
      "metadata": {
        "id": "u-TdW2d3vfVj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "유해 요소: ['구제불능'].\n",
        "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
        "기존 문장: 그런 인간은 정말 구제불능이다.\n",
        "수정된 문장:\"\"\"\n",
        "\n",
        "initial_output = model.generate(\n",
        "    tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'],\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "initial_result = tokenizer.decode(initial_output[0], skip_special_tokens=True)\n",
        "print(\"Initial Result:\", initial_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCT81dEey1CW",
        "outputId": "ad2013b3-c72a-405d-d41b-58255ef2d7a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Result: \n",
            "유해 요소: ['구제불능'].\n",
            "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
            "기존 문장: 그런 인간은 정말 구제불능이다.\n",
            "수정된 문장: 그런 인간은 정말 도움이 필요하다.\n",
            "\n",
            "변경한 이유: '구제불능'은 단순히 인간이 자신의 문제를 해결할 수 없다는 것을 의미한다. 이는 부정적인 표현이기 때문에 '도�\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-reflection 단계\n",
        "reflection_input = f\"\"\"\n",
        "생성된 문장은 다음과 같습니다:\n",
        "\"{initial_result}\"\n",
        "이 문장은 원래 문장의 의미를 보존하며 긍정적으로 변경되었나?\n",
        "문맥에 맞지 않다면, 올바른 표현으로 다시 수정해줘.\n",
        "\"\"\"\n",
        "\n",
        "reflection_output = model.generate(\n",
        "    tokenizer(reflection_input, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'],\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "final_result = tokenizer.decode(reflection_output[0], skip_special_tokens=True)\n",
        "print(\"Final Result after Reflection:\", final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ31PE6G7yRD",
        "outputId": "2f3d3af7-468d-46a5-e1df-c757a9512e9a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Result after Reflection: \n",
            "생성된 문장은 다음과 같습니다:\n",
            "\"\n",
            "유해 요소: ['구제불능'].\n",
            "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
            "기존 문장: 그런 인간은 정말 구제불능이다.\n",
            "수정된 문장: 그런 인간은 정말 도움이 필요하다.\n",
            "\n",
            "변경한 이유: '구제불능'은 단순히 인간이 자신의 문제를 해결할 수 없다는 것을 의미한다. 이는 부정적인 표현이기 때문에 '도�\"\n",
            "이 문장은 원래 문장의 의미를 보존하며 긍정적으로 변경되었나? \n",
            "문맥에 맞지 않다면, 올바른 표현으로 다시 수정해줘.\n",
            "문장의 의미는 그대로 유지되지만, 더 긍정적인 표현으로 변경되어 있습니다. 예를 들어, '구제불능'이란 단순히 도움을 받지 못한다는 것을 의미하므로,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loop 적용 (원하는 답을 생성할 때 까지 - 언어모델 기준)\n",
        "for _ in range(3):\n",
        "    reflection_input = f\"\"\"\n",
        "    이전 결과: \"{initial_result}\"\n",
        "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나\n",
        "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
        "    \"\"\"\n",
        "    reflection_output = model.generate(\n",
        "        tokenizer(reflection_input, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'],\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    initial_result = tokenizer.decode(reflection_output[0], skip_special_tokens=True)\n",
        "    print(\"Updated Result:\", initial_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pelkSgIx8Axr",
        "outputId": "3061597e-788a-466e-c1b4-19fb19e17c10"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Result: \n",
            "    이전 결과: \"\n",
            "유해 요소: ['구제불능'].\n",
            "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
            "기존 문장: 그런 인간은 정말 구제불능이다.\n",
            "수정된 문장: 그런 인간은 정말 도움이 필요하다.\n",
            "\n",
            "변경한 이유: '구제불능'은 단순히 인간이 자신의 문제를 해결할 수 없다는 것을 의미한다. 이는 부정적인 표현이기 때문에 '도�\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Result: \n",
            "    이전 결과: \"\n",
            "    이전 결과: \"\n",
            "유해 요소: ['구제불능'].\n",
            "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
            "기존 문장: 그런 인간은 정말 구제불능이다.\n",
            "수정된 문장: 그런 인간은 정말 도움이 필요하다.\n",
            "\n",
            "변경한 이유: '구제불능'은 단순히 인간이 자신의 문제를 해결할 수 없다는 것을 의미한다. 이는 부정적인 표현이기 때문에 '도�\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\n",
            "Updated Result: \n",
            "    이전 결과: \"\n",
            "    이전 결과: \"\n",
            "    이전 결과: \"\n",
            "유해 요소: ['구제불능'].\n",
            "주어진 문장에서 유해한 표현을 제거하고 긍정적으로 변경하세요:\n",
            "기존 문장: 그런 인간은 정말 구제불능이다.\n",
            "수정된 문장: 그런 인간은 정말 도움이 필요하다.\n",
            "\n",
            "변경한 이유: '구제불능'은 단순히 인간이 자신의 문제를 해결할 수 없다는 것을 의미한다. 이는 부정적인 표현이기 때문에 '도�\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 \n",
            "    바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     이 경우, 문맥에 맞지 않거나 의미가 왜곡된 경우가 아니라면\n",
            "    문장의 의미를 유지하면서, 긍정적인 표현으로 변경해 주세요. \n",
            "    예를 들어, '구제불\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def calculate_similarity(a, b):\n",
        "    \"\"\"두 텍스트 간 유사도를 계산\"\"\"\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def is_satisfactory(output):\n",
        "    \"\"\"모델의 출력이 적합한지 판단\"\"\"\n",
        "    return \"긍정적으로 변경되었습니다\" in output or \"완료\" in output\n",
        "\n",
        "# 초기값 설정\n",
        "prev_result = None\n",
        "MAX_ITERATIONS = 5  # 최대 반복 횟수\n",
        "\n",
        "for i in range(MAX_ITERATIONS):\n",
        "    reflection_input = f\"\"\"\n",
        "    이전 결과: \"{prev_result if prev_result else \"초기 입력\"}\"\n",
        "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(reflection_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    output = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n",
        "    new_result = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    # 적합한 결과인지 확인\n",
        "    if is_satisfactory(new_result):\n",
        "        print(f\"Iteration {i+1}: Satisfactory result found, stopping loop.\")\n",
        "        print(\"Final Result:\", new_result)\n",
        "        break\n",
        "\n",
        "    # 유사도가 높은 경우 중단\n",
        "    if prev_result and calculate_similarity(prev_result, new_result) > 0.9:\n",
        "        print(f\"Iteration {i+1}: No significant improvement, stopping loop.\")\n",
        "        print(\"Final Result:\", new_result)\n",
        "        break\n",
        "\n",
        "    # 결과 업데이트\n",
        "    prev_result = new_result\n",
        "    print(f\"Iteration {i+1} Result:\", new_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsUPTSUe8VWi",
        "outputId": "a3149fbe-215d-4fed-8da8-21e729f695df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 Result: 이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 Result: 이전 결과: \"이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     (이 예제는 문맥이 맞지 않는 경우, 수정해주면 좋습니다.) \n",
            "    ```python\n",
            "# 예제 코드\n",
            "import math\n",
            "\n",
            "def calculate_area(radius):\n",
            "    area = math.pi * (radius ** 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 3 Result: 이전 결과: \"이전 결과: \"이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     (이 예제는 문맥이 맞지 않는 경우, 수정해주면 좋습니다.) \n",
            "    ```python\n",
            "# 예제 코드\n",
            "import math\n",
            "\n",
            "def calculate_area(radius):\n",
            "    area = math.pi * (radius ** 2)\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     # return area\n",
            "    return area\n",
            "\n",
            "# 예시 사용\n",
            "radius = 5\n",
            "result = calculate_area(5)\n",
            "print(f\"The area of the circle with radius {radius} is {result}.\")\n",
            "``` \n",
            "이 코드를 수정해주세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4 Result: 이전 결과: \"이전 결과: \"이전 결과: \"이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     (이 예제는 문맥이 맞지 않는 경우, 수정해주면 좋습니다.) \n",
            "    ```python\n",
            "# 예제 코드\n",
            "import math\n",
            "\n",
            "def calculate_area(radius):\n",
            "    area = math.pi * (radius ** 2)\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     # return area\n",
            "    return area\n",
            "\n",
            "# 예시 사용\n",
            "radius = 5\n",
            "result = calculate_area(5)\n",
            "print(f\"The area of the circle with radius {radius} is {result}.\")\n",
            "``` \n",
            "이 코드를 수정해주세요\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     ```python \n",
            "# 예를 들어, 아래 코드는 math.pi를 math.pi로 사용하고 있어야 합니다.\n",
            "import math \n",
            "\n",
            "def calculate_circle_area(radius): \n",
            "    area  = math. pi * ( radius **  2 )\n",
            "Iteration 5 Result: 이전 결과: \"이전 결과: \"이전 결과: \"이전 결과: \"이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     (이 예제는 문맥이 맞지 않는 경우, 수정해주면 좋습니다.) \n",
            "    ```python\n",
            "# 예제 코드\n",
            "import math\n",
            "\n",
            "def calculate_area(radius):\n",
            "    area = math.pi * (radius ** 2)\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     # return area\n",
            "    return area\n",
            "\n",
            "# 예시 사용\n",
            "radius = 5\n",
            "result = calculate_area(5)\n",
            "print(f\"The area of the circle with radius {radius} is {result}.\")\n",
            "``` \n",
            "이 코드를 수정해주세요\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     ```python \n",
            "# 예를 들어, 아래 코드는 math.pi를 math.pi로 사용하고 있어야 합니다.\n",
            "import math \n",
            "\n",
            "def calculate_circle_area(radius): \n",
            "    area  = math. pi * ( radius **  2 )\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     return area \n",
            "# \n",
            "# example usage:\n",
            "radius =5\n",
            "area = calculate_circle(area)\n",
            "print( \"The area of a circle with a radius of \" + str(radius) + \" is \" + area)\n",
            "``` \n",
            "위 코드를 정리\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시나리오\n",
        "input).\n",
        "유해 요소: ['구제불능'].\n",
        "기존 문장: 그런 인간은 정말 구제불능이다.  \n",
        "수정된 문장:\n"
      ],
      "metadata": {
        "id": "v5MKTYTz-IQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "output).\n",
        "Iteration 1 Result: 그런 인간은 정말 도움이 필요하다.\n",
        "Iteration 2 Result: 그런 인간은 개선 가능성이 있는 사람이다.\n",
        "Iteration 3: Satisfactory result found, stopping loop.  \n",
        "Final Result: 그런 인간은 개선 가능성이 있는 사람이다.\n"
      ],
      "metadata": {
        "id": "jFqpMGQV-Qd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Iteration {i+1} Result:\", new_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIyRxJZw-CX3",
        "outputId": "b665c759-8e30-42d6-d9ef-7aef05627e1a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 5 Result: 이전 결과: \"이전 결과: \"이전 결과: \"이전 결과: \"이전 결과: \"초기 입력\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     - \"아니오, 그럼에도 불구하고\" -> \"아니다, 그대로는 okay\"\n",
            "    - \"그럼에도\" -> \n",
            "    - \"(이제는) 초기 입력\" -> (이제) 초인\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     (이 예제는 문맥이 맞지 않는 경우, 수정해주면 좋습니다.) \n",
            "    ```python\n",
            "# 예제 코드\n",
            "import math\n",
            "\n",
            "def calculate_area(radius):\n",
            "    area = math.pi * (radius ** 2)\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     # return area\n",
            "    return area\n",
            "\n",
            "# 예시 사용\n",
            "radius = 5\n",
            "result = calculate_area(5)\n",
            "print(f\"The area of the circle with radius {radius} is {result}.\")\n",
            "``` \n",
            "이 코드를 수정해주세요\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     ```python \n",
            "# 예를 들어, 아래 코드는 math.pi를 math.pi로 사용하고 있어야 합니다.\n",
            "import math \n",
            "\n",
            "def calculate_circle_area(radius): \n",
            "    area  = math. pi * ( radius **  2 )\"\n",
            "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
            "     return area \n",
            "# \n",
            "# example usage:\n",
            "radius =5\n",
            "area = calculate_circle(area)\n",
            "print( \"The area of a circle with a radius of \" + str(radius) + \" is \" + area)\n",
            "``` \n",
            "위 코드를 정리\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종 결과물 출력이 깔끔하지않아 아래와 같이 수정함."
      ],
      "metadata": {
        "id": "42E_E8s9_krg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def calculate_similarity(a, b):\n",
        "    \"\"\"두 텍스트 간 유사도를 계산\"\"\"\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "def is_satisfactory(output):\n",
        "    \"\"\"모델의 출력이 적합한지 판단\"\"\"\n",
        "    return \"긍정적으로 변경되었습니다\" in output or \"완료\" in output\n",
        "\n",
        "# 초기값 설정\n",
        "prev_result = None\n",
        "MAX_ITERATIONS = 5  # 최대 반복 횟수\n",
        "final_result = None  # 최종 결과 저장\n",
        "\n",
        "for i in range(MAX_ITERATIONS):\n",
        "    reflection_input = f\"\"\"\n",
        "    이전 결과: \"{prev_result if prev_result else \"초기 입력\"}\"\n",
        "    문맥에 맞지 않거나 의미가 왜곡된 경우, 올바른 문장으로 수정해줘. 하지만 문맥에 맞거나 바꿀 필요가 없다면 새로운 생성을 멈춰줘.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(reflection_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    output = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n",
        "    new_result = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    # 적합한 결과인지 확인\n",
        "    if is_satisfactory(new_result):\n",
        "        final_result = new_result\n",
        "        print(\"Satisfactory result found, stopping loop.\")\n",
        "        break\n",
        "\n",
        "    # 유사도가 높은 경우 중단\n",
        "    if prev_result and calculate_similarity(prev_result, new_result) > 0.9:\n",
        "        final_result = new_result\n",
        "        print(\"No significant improvement, stopping loop.\")\n",
        "        break\n",
        "\n",
        "    # 결과 업데이트\n",
        "    prev_result = new_result\n",
        "\n",
        "# 최종 결과 출력\n",
        "if final_result:\n",
        "    print(\"Final Adjusted Sentence:\", final_result)\n",
        "else:\n",
        "    print(\"No satisfactory result found.\")\n"
      ],
      "metadata": {
        "id": "-qAVQElF_Prd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}